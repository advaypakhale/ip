# AI Tool Usage Log

___

## Week 2

### Claude 3.5 Sonnet

- **Used for**
    - Generating a simple `AI.md` file for the project.
    - Generating sample test cases for the project.
- **Effectiveness**
    - The tool was effective in generating the initial structure of the `AI.md` file.
    - The tool was effective in generating sample test cases for the project.
- **Time Impact**
    - The tool saved time in generating the initial structure of the `AI.md` file.
    - The tool saved time in generating sample test cases for the project.
- **Challenges**
    - The tool was not able to generate all the test cases required for the project. Some human oversight was still
      required.

### GitHub Copilot

- **Used for**
    - Auto-completing code snippets throughout the project, although generally _minimally_ method signatures were still
      manually written.
- **Effectiveness**
    - The tool was effective in auto-completing basic logic and boilerplate, such as the error messages for exceptions.
- **Time Impact**
    - The tool saved time in writing boilerplate code.
- **Challenges**
    - The tool often suggested code that was not relevant to the current context, which required manual filtering.
    - The tool often generated code that did not align with the architecture of the project I had in mind.

## Week 2-5

### Claude 3.5 Sonnet

- **Used for**
    - `Level-7`: `Storage::save` and `Storage::load` were entirely generated by Claude, with some bug fixes made
      manually.
    - `Level-8`: Core functionality to parse and format dates was generated by Claude.
    - `A-JUnit`: All tests were generated by Claude.
    - `A-Javadoc`: All Javadoc were generated by Claude, then edited manually to handle slight errors or to add more
      detail.
    - `Level-10`: Both css stylesheets for the GUI components given by the teaching team were edited by Claude as
      specified by me.
- **Evaluation**
    - For "grindy" work like writing Javadocs, Claude is basically flawless, given sufficient context.
    - I managed to write something like 65-70 tests (!) with Claude's help, and only a few were not relevant or
      incorrect. Many actually helped me to find bugs in my code.
    - It was important to prompt correctly and provide sufficient context - good tests only started being generated once
      I gave Claude *all* project files at once, rather than individually. On the other hand, when working on fairly
      localised changes, polluting the context window with previous chats would show an immediate degradation of
      performance, and I had to start a new chat every time I worked on a new feature.
    - Claude doesn't understand styling components too well. I have noticed this with other forms of styling too e.g.
      react components. There is a large disparity between the visuals of what it claims it has generated and what it
      actually generates.

### GitHub Copilot

- **Used for**
    - Auto-completing code snippets throughout the project.
- **Effectiveness**
    - Copilot feels like a massive downgrade after using Claude, even after selecting the preview version of Sonnet as
      the Copilot backend. The full context of an LLM cannot be beaten by Copilot.
    - It is worth the time to copy/paste code between the IDE and Claude as compared to generating code using Copilot
      directly in the IDE; the extra time saved is not even close to making up for the difference in code quality and
      understanding.
    - Often Copilot surprises oneself by almost predicting exactly what one is about to type; however, more often than
      not, it suggests something that actively breaks your chain of thought while coding. So in the end I disabled "
      ghost suggestions" in my IDE, and only allowed Copilot suggestions through the normal code suggestion panel that
      pops up when you are only using an LSP for example.

## Week 6

### Claude 3.5 Sonnet

- **Used for**
    - `A-UserGuide`: All the `Command` subclasses' source code was passed to Claude for it to generate the section of
      the user guide on technical documentation/command use.
- **Evaluation**
    - Claude was able to infer the expected syntax of the commands and even edge cases mostly correctly, requiring
      little to no modification for its generated content.
    - However, it did hallucinate the output of the `Task` creation commands, since this output was actually defined
      within the `Task` classes, which were not passed to Claude. In hindsight, passing these files to Claude could
      have led it to infer the expected outputs correctly, although in this case the output was just corrected manually.